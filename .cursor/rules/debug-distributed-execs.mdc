---
description: Launching and monitoring a training in the cloud
globs: 
alwaysApply: false
---
# Context
The repository terraform-scalable-training hosts the ability to run distributed executions.
The workflow is as follows:
1. Usage of `veesion_data_core` to manage distributed execution requests (start, stop, resume etc.)
2. Automated triggering of github actions in `terraform-scalable-training`.
There may be several runs per request if for instance no cloud machines are available.
3. When Github actions workflows succeed, remote instance are started executing code from the Simone repository.
4. Distributed executions are monitored using logs through Grafana and eventually Sentry for errors
5. Success or failure can be checked through `veesion_data_core`

# Guidelines
When asked about debugging a particular distributed execution (any, training or inference) do not
look for any other problems you could find using tools and focus on the current task.

First look for existing trainings, and if not launch one.
Then debug it and relaunch it after fixing.

# Tools
## Debugging
When debugging a distributed execution, it is important to use the following tools in that exact order:
1. The monitoring script `scripts/utils/wait_and_monitor.py my-training-name --wait`
    - Discovers training instances from GitHub Actions workflows / 
    checks using `veesion_data_core` for training request status
    - Extracts instance IPs from workflow logs
    - Example usage: `python3 scripts/utils/wait_and_monitor.py my-training-name --wait` (should use the python venv)
    Always run this command directly, never launch it in a terminal, so that we automatically prompt you when its results are shown. 
2. If there is a Github error in the wf, use mdc:.cursor/rules/reach-github
3. Sentry to look for errors reported, use mdc:.cursor/rules/reach-sentry
4. Grafana to look for logs, use mdc:.cursor/rules/reach-grafana

## Manage distributed trainings
To manage distributed training, use `veesion_data_core` (in the venv):
```python
# These are the only functions that exist in veesion_data_core
# not invent any other one
from veesion_data_core.tools import (
    request_training,
    resume_training,
    stop_training,
    update_training_n_epochs,
)

# Start a training
request_training(
    training_name="my-training-name",
    dataset_version=27,
    cpu_instances_count=1,  # one instance only for debugging
    gpu_instances_count=1,  # one instance only for debugging
    n_epochs=1,  # one epoch only for debugging
    simone_branch="master",  # branch used for debugging
)
```
1. Make sure to choose the branch you are working on in Simone
2. Choose a training name used to monitor
```python
# Get the training request for monitoring
training_request = get_training_request(training_name="my-training-name")

print("Training name:", training_request.training_name)
print("Training status:", training_request.status)
print("Number of Training Run attempted ", training_request.scheduling_attempt)
```
3. To restart a training after a failure:
```python
resume_training(
    training_name="my-training-name",
    force_resume=True
)
```

- If the training does not exist, it most likely means it was never started.
- If you want your code changes to be applied to a training, they must be pushed 
on the remote branch named as the "simone_branch" argument for the Simone repository
- Trainings take time to start, you must wait at least 2 minutes before. When you debug a training, wait and regularly check for errors until it is completed
a training start and any debugging attempt.
- When you print objects from `veesion_data_core`, don't try to access attributes,
just use the default display, it should be readable directly
